{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f089c81",
   "metadata": {},
   "source": [
    "# Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c026725",
   "metadata": {},
   "source": [
    "This notebook focuses on the practical application of various regularisation methods to prevent overfitting in machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64631b9e",
   "metadata": {},
   "source": [
    "Here is the link to the dataset to be used: https://raw.githubusercontent.com/Explore-AI/Public-Data/master/SDG_15_Life_on_Land_Dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc34d6",
   "metadata": {},
   "source": [
    "### Step 1: Data scaling\n",
    "\n",
    "Before applying regularisation techniques, it's crucial to scale the data. Therefore, scale the features of the `SDG_15_Life_on_Land_Dataset` to have a mean of `0` and a standard deviation of `1`.\n",
    "\n",
    "We start by doing the following:\n",
    "\n",
    "- Load the dataset and select features for scaling (exclude the `Year` column).\n",
    "- Implement standard scaling on the selected features.\n",
    "- Display the first five rows of the scaled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b9cf51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WaterQualityIndex</th>\n",
       "      <th>ClimateChangeImpactScore</th>\n",
       "      <th>LandUseChange</th>\n",
       "      <th>InvasiveSpeciesCount</th>\n",
       "      <th>ConservationFunding</th>\n",
       "      <th>EcoTourismImpact</th>\n",
       "      <th>ForestCoverChange</th>\n",
       "      <th>SoilQualityIndex</th>\n",
       "      <th>WaterUsage</th>\n",
       "      <th>RenewableEnergyUsage</th>\n",
       "      <th>CarbonEmissionLevels</th>\n",
       "      <th>AgriculturalIntensity</th>\n",
       "      <th>HabitatConnectivity</th>\n",
       "      <th>SpeciesReintroductionEfforts</th>\n",
       "      <th>PollinatorDiversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.509823</td>\n",
       "      <td>0.915895</td>\n",
       "      <td>0.532798</td>\n",
       "      <td>0.967295</td>\n",
       "      <td>-0.129430</td>\n",
       "      <td>-1.297085</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>0.689812</td>\n",
       "      <td>-0.641157</td>\n",
       "      <td>-1.290990</td>\n",
       "      <td>-0.930835</td>\n",
       "      <td>-1.237558</td>\n",
       "      <td>-1.131411</td>\n",
       "      <td>1.494660</td>\n",
       "      <td>-0.811078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.261473</td>\n",
       "      <td>-1.159761</td>\n",
       "      <td>0.479063</td>\n",
       "      <td>1.382383</td>\n",
       "      <td>-1.098165</td>\n",
       "      <td>1.226669</td>\n",
       "      <td>-1.649745</td>\n",
       "      <td>0.655167</td>\n",
       "      <td>0.539995</td>\n",
       "      <td>0.207271</td>\n",
       "      <td>0.470716</td>\n",
       "      <td>-0.670150</td>\n",
       "      <td>0.305779</td>\n",
       "      <td>-0.107952</td>\n",
       "      <td>0.797582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.363971</td>\n",
       "      <td>-1.409483</td>\n",
       "      <td>1.389846</td>\n",
       "      <td>0.206299</td>\n",
       "      <td>0.320340</td>\n",
       "      <td>-0.529103</td>\n",
       "      <td>-0.877370</td>\n",
       "      <td>0.759101</td>\n",
       "      <td>1.165311</td>\n",
       "      <td>-0.473757</td>\n",
       "      <td>-0.110415</td>\n",
       "      <td>1.006319</td>\n",
       "      <td>1.598836</td>\n",
       "      <td>-1.017291</td>\n",
       "      <td>-1.518029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.475658</td>\n",
       "      <td>0.746916</td>\n",
       "      <td>0.684528</td>\n",
       "      <td>0.828932</td>\n",
       "      <td>1.323673</td>\n",
       "      <td>1.653728</td>\n",
       "      <td>1.188117</td>\n",
       "      <td>0.481943</td>\n",
       "      <td>1.165311</td>\n",
       "      <td>1.535274</td>\n",
       "      <td>0.368164</td>\n",
       "      <td>-1.360736</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>-0.978326</td>\n",
       "      <td>-1.249998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.885648</td>\n",
       "      <td>1.230038</td>\n",
       "      <td>-0.213905</td>\n",
       "      <td>1.105658</td>\n",
       "      <td>1.323673</td>\n",
       "      <td>1.445945</td>\n",
       "      <td>-0.439815</td>\n",
       "      <td>-1.319584</td>\n",
       "      <td>-1.787570</td>\n",
       "      <td>1.160709</td>\n",
       "      <td>0.402348</td>\n",
       "      <td>1.675792</td>\n",
       "      <td>-0.977884</td>\n",
       "      <td>0.832482</td>\n",
       "      <td>1.077254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WaterQualityIndex  ClimateChangeImpactScore  LandUseChange  \\\n",
       "0          -0.509823                  0.915895       0.532798   \n",
       "1          -1.261473                 -1.159761       0.479063   \n",
       "2          -1.363971                 -1.409483       1.389846   \n",
       "3          -0.475658                  0.746916       0.684528   \n",
       "4          -0.885648                  1.230038      -0.213905   \n",
       "\n",
       "   InvasiveSpeciesCount  ConservationFunding  EcoTourismImpact  \\\n",
       "0              0.967295            -0.129430         -1.297085   \n",
       "1              1.382383            -1.098165          1.226669   \n",
       "2              0.206299             0.320340         -0.529103   \n",
       "3              0.828932             1.323673          1.653728   \n",
       "4              1.105658             1.323673          1.445945   \n",
       "\n",
       "   ForestCoverChange  SoilQualityIndex  WaterUsage  RenewableEnergyUsage  \\\n",
       "0           0.017923          0.689812   -0.641157             -1.290990   \n",
       "1          -1.649745          0.655167    0.539995              0.207271   \n",
       "2          -0.877370          0.759101    1.165311             -0.473757   \n",
       "3           1.188117          0.481943    1.165311              1.535274   \n",
       "4          -0.439815         -1.319584   -1.787570              1.160709   \n",
       "\n",
       "   CarbonEmissionLevels  AgriculturalIntensity  HabitatConnectivity  \\\n",
       "0             -0.930835              -1.237558            -1.131411   \n",
       "1              0.470716              -0.670150             0.305779   \n",
       "2             -0.110415               1.006319             1.598836   \n",
       "3              0.368164              -1.360736             0.001642   \n",
       "4              0.402348               1.675792            -0.977884   \n",
       "\n",
       "   SpeciesReintroductionEfforts  PollinatorDiversity  \n",
       "0                      1.494660            -0.811078  \n",
       "1                     -0.107952             0.797582  \n",
       "2                     -1.017291            -1.518029  \n",
       "3                     -0.978326            -1.249998  \n",
       "4                      0.832482             1.077254  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing the CSV file to be used as a pandas DataFrame\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/SDG_15_Life_on_Land_Dataset.csv')\n",
    "\n",
    "# Setting the predictors(excluding year) and response variables\n",
    "y = df['BiodiversityHealthIndex']\n",
    "X_temp = df.drop(columns=['Year', 'BiodiversityHealthIndex'])\n",
    "\n",
    "# Standardising the predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_temp_scaled = pd.DataFrame(scaler.fit_transform(X_temp), columns=X_temp.columns)\n",
    "\n",
    "# Displaying the first five rows of the standardised DataFrame\n",
    "X_temp_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1773c59b",
   "metadata": {},
   "source": [
    "### Step 2: Ridge regression\n",
    "\n",
    "Ridge regression is a technique used to analyse multiple regression data that suffer from multicollinearity. By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors.\n",
    "\n",
    "In this step, we do the following:\n",
    "\n",
    "- Use the scaled features from **Step 1** as your predictors and select a suitable target variable from the dataset.\n",
    "- Split the data into training and test sets.\n",
    "- Implement a ridge regression model, with cross-validation to find the optimal regularisation parameter.\n",
    "- Evaluate the model on the test set and report the R-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "febadcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal regularisation parameter: {'alpha': 20}\n",
      "R-squared value on the test set: -0.059838872264527554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Splitting the data into testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ridge regression model with cross-validation\n",
    "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
    "model_r = GridSearchCV(Ridge(), parameters, scoring='r2', cv=5)\n",
    "model_r.fit(X_train, y_train)\n",
    "\n",
    "# Generating predictions from the test set\n",
    "y_pred_r = model_r.predict(X_test)\n",
    "\n",
    "# Getting the R squared score of the model\n",
    "r2 = r2_score(y_test, y_pred_r)\n",
    "\n",
    "#Printing out the results\n",
    "print(f\"Optimal regularisation parameter: {model_r.best_params_}\")\n",
    "print(f\"R-squared value on the test set: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54898f",
   "metadata": {},
   "source": [
    "The ridge regression technique is particularly useful when dealing with multicollinearity, helping to reduce the variance of the coefficients and improve the model's generalisation ability. The task involves selecting a target variable, splitting the data into training and test sets, implementing ridge regression with cross-validation to find the best regularisation parameter (`alpha`), and finally, evaluating the model's performance on the test set using the R-squared metric. The R-squared value will indicate how well the model explains the variance in the target variable.\n",
    "\n",
    "**Interpretation**: The R-squared value reported from the ridge regression model evaluation signifies the proportion of the variance in the dependent variable that is predictable from the independent variables. In simple terms, it reflects the goodness of fit of the model. A value closer to 1 indicates a model that perfectly predicts the target variable, whereas a value closer to 0 indicates a model that fails to accurately predict the target variable's variance. It should be noted that an R-squared value of 1 suggests possible overfitting and it should be treated with caution. Investigating the individual variables and their coefficients might add more insight to whether the model has been overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3f4e4",
   "metadata": {},
   "source": [
    "### Step 3: LASSO regression\n",
    "\n",
    "LASSO (Least Absolute Shrinkage and Selection Operator) regression is a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean.\n",
    "\n",
    "In this step, we do the following:\n",
    "\n",
    "- Re-use the scaled features and target variable from the previous exercises.\n",
    "- Split the data into training and test sets.\n",
    "- Implement a LASSO regression model, with cross-validation to find the optimal regularisation parameter.\n",
    "- Evaluate the model on the test set and report the R-squared value and the number of features used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4be3089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal regularisation parameter: 0.023673211125955964\n",
      "R squared: -0.020436824594975977\n",
      "Number of features used: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Splitting the data into testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fitting the LASSO regression model on our data with cross validation\n",
    "model_l = LassoCV(cv=5, random_state=42)\n",
    "model_l.fit(X_train, y_train)\n",
    "\n",
    "# Generating predictions from the test set\n",
    "y_pred_l = model_l.predict(X_test)\n",
    "\n",
    "# Getting the R squared score of the model\n",
    "rsq_score = r2_score(y_test, y_pred_l)\n",
    "features_used = np.sum(model_l.coef_ != 0)\n",
    "\n",
    "# Printing out the results\n",
    "print(f'Optimal regularisation parameter: {model_l.alpha_}')\n",
    "print(f'R squared: {rsq_score}')\n",
    "print(f'Number of features used: {features_used}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba46c6",
   "metadata": {},
   "source": [
    "LASSO regression is beneficial for models that suffer from multicollinearity or when it's necessary to reduce the number of features in a model. LASSO does this by applying a penalty to the absolute size of the coefficients, effectively shrinking some of them to zero and thus excluding them from the model. This exercise involves reusing the scaled features and target variable, splitting the dataset, implementing LASSO regression with cross-validation to identify the optimal alpha, and evaluating the model. The output includes the R-squared value, which assesses the model's fit, and the count of features used, demonstrating LASSO's capability for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d25562",
   "metadata": {},
   "source": [
    "**Interpretation**: The R-squared value here, similar to ridge regression, measures how well the observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model. Moreover, the number of features used by the LASSO model highlights its ability to perform feature selection, reducing the complexity of the model and potentially enhancing its interpretability by retaining only the most informative predictors. The reduction in the number of features used in this LASSO model suggests that we should be reassessing whether the features included in the ridge regression model were really adding value. Try to run the ridge regression again with fewer feature variables, including only the relevant features from the LASSO model to see how the results change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
